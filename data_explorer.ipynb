{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "\n",
    "files = glob.glob('data/NIfTI/NIIori/Nor/*.nii.gz') + glob.glob('data/NIfTI/NIIori/PD/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeViewer:\n",
    "    def __init__(self, volume):\n",
    "        self.volume = volume\n",
    "        self.axis = 0\n",
    "        print(f'Volume shape: {self.volume.shape}')\n",
    "        axis_selector = ipw.ToggleButtons(\n",
    "            options=[i for i in range(3)],\n",
    "            description='Axis to view:'\n",
    "        )\n",
    "        ipw.interact(self.axis_setter, axis=axis_selector)\n",
    "\n",
    "    def show_slices(self, idx):\n",
    "        print(f'Args: {idx}')\n",
    "        slc = np.take(self.volume, idx, axis=self.axis)\n",
    "        plt.imshow(slc, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    def axis_setter(self, axis):\n",
    "        self.axis = axis\n",
    "        slice_selector = ipw.IntSlider(\n",
    "            min=0, max=self.volume.shape[axis]-1,\n",
    "            continuous_update=False,\n",
    "            description='Slice index:'\n",
    "        )\n",
    "        ipw.interact(self.show_slices, idx=slice_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_nifti_file(fname):\n",
    "    volume = nib.load(fname).get_fdata()\n",
    "    VolumeViewer(volume)\n",
    "\n",
    "ipw.interact(view_nifti_file, fname=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display slices in one view (gridview)\n",
    "\n",
    "def display_volume_slices(volume, axis=0, cols=10, fig_width=10):\n",
    "    n_slices = volume.shape[axis]\n",
    "    rows = np.ceil(n_slices / cols).astype(int)\n",
    "    fig = plt.figure(figsize=(rows * fig_width, fig_width))\n",
    "\n",
    "    for idx in range(n_slices):\n",
    "        slc = np.take(volume, idx, axis=axis)\n",
    "        ax = fig.add_subplot(rows, cols, idx+1)\n",
    "        ax.imshow(slc, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "volume = nib.load('data/NIfTI_std/NIIori_std/Nor/Nor108_std.nii.gz').get_fdata()\n",
    "display_volume_slices(volume, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NIfTI file viewer widget\n",
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as ipw\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "class NiftiViewer(ipw.VBox):\n",
    "    def __init__(self, fname, figsize=(4, 4)):\n",
    "        self.nii = nib.load(fname)\n",
    "        self.vol = self.nii.get_fdata()\n",
    "        \n",
    "        axcodes= nib.aff2axcodes(self.nii.affine)\n",
    "        self.ax_selector = ipw.ToggleButtons(\n",
    "            options=[(axcode, i) for i, axcode in enumerate(axcodes)],\n",
    "            description='Orientation: '\n",
    "        )\n",
    "        self.slc_selector = ipw.IntSlider(\n",
    "            min=0, max=self.vol.shape[self.ax_selector.value]-1,\n",
    "            description='Slice index:'\n",
    "        )\n",
    "        self.ax_selector.observe(self.set_axis, 'value')\n",
    "        self.slc_selector.observe(self.set_slice, 'value')\n",
    "\n",
    "        output = ipw.Output()\n",
    "        with output:\n",
    "            print(f'{fname} | {self.vol.shape}')\n",
    "            self.fig, self.ax = plt.subplots(figsize=figsize)\n",
    "        self.fig.canvas.header_visible = False\n",
    "        self.fig.canvas.footer_visible = False\n",
    "        self.fig.canvas.toolbar_visible = False\n",
    "\n",
    "        super().__init__([self.ax_selector, self.slc_selector, output])\n",
    "        self.set_axis({'new': 0})\n",
    "\n",
    "    def set_axis(self, change):\n",
    "        self.slc_selector.max = self.vol.shape[change['new']] - 1\n",
    "        self.slc_selector.value = self.vol.shape[change['new']] // 2\n",
    "        self.set_slice({'new': self.vol.shape[change['new']] // 2})\n",
    "        \n",
    "    def set_slice(self, change):\n",
    "        self.ax.axis('off')\n",
    "        self.ax.imshow(\n",
    "            self.vol.take(indices=change['new'], axis=self.ax_selector.value),\n",
    "            cmap='gray'\n",
    "        )\n",
    "\n",
    "NiftiViewer('data/NIfTI_std/NIIori_std/Nor/Nor108_std.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check orientation and dimension of nifti files\n",
    "files = glob.glob('data/NIfTI_std/NIIori_std/Nor/*')\n",
    "for f in files:\n",
    "    img = nib.load(f)\n",
    "    print(f'{f.split(\"/\")[-1]}: {img.shape} {nib.aff2axcodes(img.affine)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using animation to show slices\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "def vol_viewer(fname, figsize=(6, 6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    nii = nib.load(fname)\n",
    "    vol = nii.get_fdata()\n",
    "    plt_img = plt.imshow(vol[0], cmap='gray')\n",
    "    \n",
    "    def slice_viewer(idx):\n",
    "        plt_img.set_array(vol[idx])\n",
    "        return [plt_img]\n",
    "    \n",
    "    return animation.FuncAnimation(fig, slice_viewer, frames=len(vol), interval=1000//24)\n",
    "\n",
    "vol_viewer('data/NIfTI_std/NIIori_std/Nor/Nor108_std.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nii1: ('P', 'S', 'R') | nii2: ('R', 'A', 'S')\n",
      "Volume shape: (256, 256, 178)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3c430be2e74866b8b277b09ce67cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Axis to view:', options=(0, 1, 2), value=0), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "Volume shape: (178, 256, 256)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953c904a31e144e6b72c2bce9756cc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Axis to view:', options=(0, 1, 2), value=0), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 178) (256, 256, 178)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nii1 = nib.load('data/NIfTI/NIIori/Nor/Nor108.nii.gz')\n",
    "nii2 = nib.load('data/NIfTI_std/NIIori_std/Nor/Nor108_std.nii.gz')\n",
    "print(f'nii1: {nib.aff2axcodes(nii1.affine)} | nii2: {nib.aff2axcodes(nii2.affine)}')\n",
    "VolumeViewer(nii1.get_fdata())\n",
    "print('===================================================')\n",
    "VolumeViewer(nii2.get_fdata())\n",
    "\n",
    "## Check if nii2 same as nii1 after reorientation\n",
    "end_ornt = nib.orientations.axcodes2ornt(('P', 'S', 'R'))\n",
    "start_ornt = nib.orientations.axcodes2ornt(nib.aff2axcodes(nii2.affine))\n",
    "transform_ornt = nib.orientations.ornt_transform(start_ornt, end_ornt)\n",
    "print(nii1.get_fdata().shape, nib.apply_orientation(nii2.get_fdata(), transform_ornt).shape)\n",
    "np.array_equal(\n",
    "    nii1.get_fdata(),\n",
    "    nib.apply_orientation(nii2.get_fdata(), transform_ornt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 477/1740 [02:41<46:33,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/NIfTI/NIIorisk/Nor/Nor105sk.nii.gz ((512, 512, 256)) | data/NIfTI_std/NIIorisk_std/Nor/Nor105sk_std.nii.gz ((512, 512, 256)) : result in different orientation.\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1320/1740 [21:42<12:20,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/NIfTI/NIIoriss/Nor/Nor105ss.nii.gz ((512, 512, 256)) | data/NIfTI_std/NIIoriss_std/Nor/Nor105ss_std.nii.gz ((512, 512, 256)) : result in different orientation.\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1740/1740 [31:25<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "fnames = glob.glob('data/NIfTI/*/*/*.nii.gz')\n",
    "end_ornt = nib.orientations.axcodes2ornt(('P', 'S', 'R'))\n",
    "\n",
    "for fname in tqdm(fnames):\n",
    "    tkns = fname[:-7].split('/')\n",
    "    for i in [1, 2, -1]:\n",
    "        tkns[i] += '_std'\n",
    "    fname_std = f'{\"/\".join(tkns)}.nii.gz'\n",
    "    \n",
    "    nii = nib.load(fname)\n",
    "    nii_std = nib.load(fname_std)\n",
    "    tornt = nib.orientations.ornt_transform(\n",
    "        nib.io_orientation(nii.affine), # or use this nib.orientations.axcodes2ornt(nib.aff2axcodes(nii.affine)),\n",
    "        end_ornt\n",
    "    )\n",
    "    tornt_std = nib.orientations.ornt_transform(\n",
    "        nib.io_orientation(nii_std.affine), # or use this nib.orientations.axcodes2ornt(nib.aff2axcodes(nii_std.affine)),\n",
    "        end_ornt\n",
    "    )\n",
    "    nii_img = nib.apply_orientation(nii.get_fdata(), tornt)\n",
    "    nii_img_std = nib.apply_orientation(nii_std.get_fdata(), tornt_std)\n",
    "    \n",
    "    if not np.allclose(nii_img, nii_img_std): # array_equal is too strict!\n",
    "        print(\n",
    "            f'{fname} ({nii_img.shape}) | {fname_std} ({nii_img_std.shape}) : result in different orientation.'\n",
    "        )\n",
    "        print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import io\n",
    "\n",
    "from utils import Params\n",
    "from util.gradcam import gradcam\n",
    "\n",
    "def plot_3d_gradcam_grid(fname, model, layer_name, labels=['Nor', 'PD']):\n",
    "    ### Load and resize nii image\n",
    "    volume_size = model.input_shape[1:-1]\n",
    "    img = nib.load(fname)\n",
    "    input_img = resize(img.get_fdata(), volume_size, order=1, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    ### Predict and receive gradcam heatmap\n",
    "    pred = model(np.expand_dims(input_img, axis=(0, -1)))[0]\n",
    "    cls_idx = np.argmax(pred)\n",
    "    heatmap = gradcam(np.expand_dims(input_img, axis=(0, -1)), model, layer_name)\n",
    "    heatmap = resize(heatmap, volume_size, order=1, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    ### Normalize both input_img and heatmap, then convert into uint8\n",
    "    input_img = (input_img - np.min(input_img)) / (np.max(input_img) - np.min(input_img))\n",
    "    input_img = np.uint8(255 * input_img)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    ### Reorientate input_img and heatmap\n",
    "    transform = nib.orientations.ornt_transform(\n",
    "        nib.io_orientation(img.affine),\n",
    "        nib.orientations.axcodes2ornt('PSR')\n",
    "    )\n",
    "    input_img = nib.apply_orientation(input_img, transform)\n",
    "    heatmap = nib.apply_orientation(heatmap, transform)\n",
    "    \n",
    "    ### Visualize in a grid\n",
    "    ncols = 10\n",
    "    nrows = np.ceil(input_img.shape[1] / ncols).astype(int)\n",
    "    fig, axarr = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows))\n",
    "    for i, ax in enumerate(axarr.ravel()):\n",
    "        if i < input_img.shape[1]:\n",
    "            slc = input_img.take(i, axis=1)\n",
    "            slc = np.repeat(np.expand_dims(slc, -1), 3, axis=-1)\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            plt.imsave(buf, heatmap.take(i, axis=1), format='jpg', cmap='jet')\n",
    "            buf.seek(0)\n",
    "            hmap = plt.imread(buf, format='jpg')\n",
    "\n",
    "            ax.imshow(cv2.addWeighted(slc, 0.6, hmap, 0.4, 0))\n",
    "            ax.set_aspect('auto')\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f'[{layer_name}] {fname.split(\"/\")[-1]} | {labels[cls_idx]} ({pred[cls_idx] * 100:.2f} %)', fontsize=80)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "exp_types = ['ori', 'oriss', 'orisk', 'reg']\n",
    "for exp_type in exp_types:\n",
    "    exp_dir = f'thesis_exp/3dcnn/{exp_type}'\n",
    "    gradcam_dir = f'{exp_dir}/gradcam_result'\n",
    "    os.makedirs(gradcam_dir)\n",
    "    print(f'Creating 3D Grad-CAM for {exp_dir}...')\n",
    "    \n",
    "    params = Params(f'{exp_dir}/train_params.json')\n",
    "    df = pd.read_csv(params.data)\n",
    "    X, y = df.Fpath.values, df.Label.values\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, stratify=y, train_size=0.85, random_state=params.seed)\n",
    "    model = tf.keras.models.load_model(f'{exp_dir}/model_best.h5')\n",
    "    for fname in tqdm(X_ts):\n",
    "        fig = plot_3d_gradcam_grid(fname, model, 'conv3d_3')\n",
    "        fig.savefig(f'{gradcam_dir}/{fname.split(\"/\")[-1].replace(\".nii.gz\", \"\")}.jpg')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Attention Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import io\n",
    "\n",
    "from models import find_model\n",
    "from utils import Params\n",
    "from util.vis import attention_map\n",
    "\n",
    "def plot_attn_map_grid(fname, model, labels=['Nor', 'PD']):\n",
    "    ### Load and resize nii image\n",
    "    volume_size = model.input_shape[1:-1]\n",
    "    img = nib.load(fname)\n",
    "    input_img = resize(img.get_fdata(), volume_size, order=1, mode='constant', anti_aliasing=True)\n",
    "    \n",
    "    ### Predict and receive attention map mask\n",
    "    pred = model(np.expand_dims(input_img, axis=(0, -1)))[0]\n",
    "    cls_idx = np.argmax(pred)\n",
    "    mask = attention_map(np.expand_dims(input_img, axis=(0, -1)), model)\n",
    "    mask = resize(mask, volume_size, order=1, mode='constant', anti_aliasing=True)\n",
    "\n",
    "    ### Normalize both input_img and mask, then convert into uint8\n",
    "    input_img = (input_img - np.min(input_img)) / (np.max(input_img) - np.min(input_img))\n",
    "    input_img = np.uint8(255 * input_img)\n",
    "    mask = np.uint8(255 * mask)\n",
    "\n",
    "    ### Reorientate input_img and mask\n",
    "    transform = nib.orientations.ornt_transform(\n",
    "        nib.io_orientation(img.affine),\n",
    "        nib.orientations.axcodes2ornt('PSR')\n",
    "    )\n",
    "    input_img = nib.apply_orientation(input_img, transform)\n",
    "    mask = nib.apply_orientation(mask, transform)\n",
    "    \n",
    "    ### Visualize in a grid\n",
    "    ncols = 10\n",
    "    nrows = np.ceil(input_img.shape[1] / ncols).astype(int)\n",
    "    fig, axarr = plt.subplots(nrows, ncols, figsize=(5*ncols, 5*nrows))\n",
    "    for i, ax in enumerate(axarr.ravel()):\n",
    "        if i < input_img.shape[1]:\n",
    "            slc = input_img.take(i, axis=1)\n",
    "            slc = np.repeat(np.expand_dims(slc, -1), 3, axis=-1)\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            plt.imsave(buf, mask.take(i, axis=1), format='jpg', cmap='jet')\n",
    "            buf.seek(0)\n",
    "            hmap = plt.imread(buf, format='jpg')\n",
    "\n",
    "            ax.imshow(cv2.addWeighted(slc, 0.6, hmap, 0.4, 0))\n",
    "            ax.set_aspect('auto')\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(f'{fname.split(\"/\")[-1]} | {labels[cls_idx]} ({pred[cls_idx] * 100:.2f} %)', fontsize=80)\n",
    "\n",
    "    return fig\n",
    "\n",
    "exp_types = ['ori', 'oriss', 'orisk', 'reg']\n",
    "for exp_type in exp_types:\n",
    "    exp_dir = f'thesis_exp/3dvit/{exp_type}'\n",
    "    attn_map_dir = f'{exp_dir}/attn_maps'\n",
    "    os.makedirs(attn_map_dir)\n",
    "    print(f'Creating attention map for {exp_dir}...')\n",
    "\n",
    "    params = Params(f'{exp_dir}/train_params.json')\n",
    "    df = pd.read_csv(params.data)\n",
    "    X, y = df.Fpath.values, df.Label.values\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, stratify=y, train_size=0.85, random_state=params.seed)\n",
    "    model_params = {'classes': 2}\n",
    "    if hasattr(params, 'model_params'):\n",
    "        model_params.update(params.model_params)\n",
    "    model = find_model(params.model)(input_shape=(*params.volume_size, 1), **model_params)\n",
    "    model.load_weights(f'{exp_dir}/model_best.h5')\n",
    "    for fname in tqdm(X_ts):\n",
    "        fig = plot_attn_map_grid(fname, model)\n",
    "        fig.savefig(f'{attn_map_dir}/{fname.split(\"/\")[-1].replace(\".nii.gz\", \"\")}.jpg')\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c021d63f56a526629ba248a242805a0e7d37bf1a9fb0abee002abf567951a528"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
